{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "with open (\"/Users/alp/Desktop/Spacey/Gervain.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The emergence of language has intrigued scientists and the general public alike, but it was only in the second half of the twentieth century that a systematic empirical investigation of language acquisition began. This work was greatly inspired by the suggestion that the environment is mainly a trigger rather than a tutor for language acquisition, at least during the first years of life (Chomsky 1959). Consequently, to explain the uniquely human capacity of language, scholars proposed innate acquisition mechanisms, specific to language (Chomsky 1959). A few years later, research into the biological foundations of language was expanded, giving a better grasp of the innate dispositions\n",
      "for language acquisition (Lenneberg 1967). \n",
      "By contrast, other researchers suggested that classical learning mechanisms, ones that humans share with other animals, may be sufficient to acquire language (Elman 1996, Tomasello 2000). Under this view, the human specificity of language arises from quantitative rather than qualitative differences between the species.\n",
      "Some of these theoretical questions may be resolved by studying preverbal infants, in particular newborns, as this allows us to determine how much of our language acquisition abilities are due to dispositions detectable much before the surroundings have shaped our cognitive apparatus. Therefore, our review mostly focuses on the development of language\n",
      "and its underlying mechanisms during the first year of life. \n",
      "This choice is also justified by the growing body of research and recent advances in understanding how different mechanisms, such as statistical and distributional learning, rule extraction, as well as perceptual and memory constraints, work together during language development.\n",
      "Our review discusses landmarks in language acquisition as well as their biological underpinnings. We focus on studies that connect brain, mind, and behavior. We believe that building bridges between these different levels is the way of the future and that the next decades will see the success of such integrative methodology and theory building.\n",
      "In the review, we first describe the different theoretical approaches to language acquisition. We then review the increasingly important and fast-growing body of literature on the biological foundations of human language, focusing mostly on genetic and evolutionary aspects. Then we review the empirical evidence that has accumulated over the past decades in support of the theories and approaches introduced. We discuss the findings following the levels of organization in language from phonology through word segmentation and lexical acquisition to grammar. Finally, we consider some of the novel empirical findings that relate to the neural basis of language acquisition and processing in newborns and young infants. Building on these empirical findings, we argue for an integrative theory of language acquisition, proposing that rule learning, perceptual bootstrapping, and statistical learning all contribute to different levels of language acquisition, and that the most interesting objective is to understand their interactions and the division of labor among them.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of all the sentences in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 The emergence of language has intrigued scientists and the general public alike, but it was only in the second half of the twentieth century that a systematic empirical investigation of language acquisition began.\n",
      "1 This work was greatly inspired by the suggestion that the environment is mainly a trigger rather than a tutor for language acquisition, at least during the first years of life (Chomsky 1959).\n",
      "2 Consequently, to explain the uniquely human capacity of language, scholars proposed innate acquisition mechanisms, specific to language (Chomsky 1959).\n",
      "3 A few years later, research into the biological foundations of language was expanded, giving a better grasp of the innate dispositions\n",
      "for language acquisition (Lenneberg 1967). \n",
      "\n",
      "4 By contrast, other researchers suggested that classical learning mechanisms, ones that humans share with other animals, may be sufficient to acquire language (Elman 1996, Tomasello 2000).\n",
      "5 Under this view, the human specificity of language arises from quantitative rather than qualitative differences between the species.\n",
      "\n",
      "6 Some of these theoretical questions may be resolved by studying preverbal infants, in particular newborns, as this allows us to determine how much of our language acquisition abilities are due to dispositions detectable much before the surroundings have shaped our cognitive apparatus.\n",
      "7 Therefore, our review mostly focuses on the development of language\n",
      "and its underlying mechanisms during the first year of life. \n",
      "\n",
      "8 This choice is also justified by the growing body of research and recent advances in understanding how different mechanisms, such as statistical and distributional learning, rule extraction, as well as perceptual and memory constraints, work together during language development.\n",
      "\n",
      "9 Our review discusses landmarks in language acquisition as well as their biological underpinnings.\n",
      "10 We focus on studies that connect brain, mind, and behavior.\n",
      "11 We believe that building bridges between these different levels is the way of the future and that the next decades will see the success of such integrative methodology and theory building.\n",
      "\n",
      "12 In the review, we first describe the different theoretical approaches to language acquisition.\n",
      "13 We then review the increasingly important and fast-growing body of literature on the biological foundations of human language, focusing mostly on genetic and evolutionary aspects.\n",
      "14 Then we review the empirical evidence that has accumulated over the past decades in support of the theories and approaches introduced.\n",
      "15 We discuss the findings following the levels of organization in language from phonology through word segmentation and lexical acquisition to grammar.\n",
      "16 Finally, we consider some of the novel empirical findings that relate to the neural basis of language acquisition and processing in newborns and young infants.\n",
      "17 Building on these empirical findings, we argue for an integrative theory of language acquisition, proposing that rule learning, perceptual bootstrapping, and statistical learning all contribute to different levels of language acquisition, and that the most interesting objective is to understand their interactions and the division of labor among them.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#list all of the sentences in the document with their list index numbers \n",
    "for i, sent in enumerate(doc.sents):\n",
    "    print(i, sent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code down below measures the similarity of each sentence with each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 0.9297234416007996\n",
      "0 2 0.8441457748413086\n",
      "0 3 0.9266768097877502\n",
      "0 4 0.7899712324142456\n",
      "0 5 0.925125002861023\n",
      "0 6 0.8560572862625122\n",
      "0 7 0.9392214417457581\n",
      "0 8 0.8979479670524597\n",
      "0 9 0.8055269718170166\n",
      "0 10 0.7147533297538757\n",
      "0 11 0.9197076559066772\n",
      "0 12 0.8509125709533691\n",
      "0 13 0.904289960861206\n",
      "0 14 0.9377974271774292\n",
      "0 15 0.9032106399536133\n",
      "0 16 0.9278295636177063\n",
      "0 17 0.9142584204673767\n",
      "1 0 0.9297234416007996\n",
      "1 2 0.8482668399810791\n",
      "1 3 0.934273898601532\n",
      "1 4 0.8224436640739441\n",
      "1 5 0.8933923840522766\n",
      "1 6 0.8096685409545898\n",
      "1 7 0.8789430856704712\n",
      "1 8 0.8916823863983154\n",
      "1 9 0.7799533009529114\n",
      "1 10 0.6866056323051453\n",
      "1 11 0.8543907999992371\n",
      "1 12 0.7966938018798828\n",
      "1 13 0.846263587474823\n",
      "1 14 0.8611082434654236\n",
      "1 15 0.8446451425552368\n",
      "1 16 0.8605772852897644\n",
      "1 17 0.8662689924240112\n",
      "2 0 0.8441457748413086\n",
      "2 1 0.8482668399810791\n",
      "2 3 0.8904719352722168\n",
      "2 4 0.9118756055831909\n",
      "2 5 0.8857656717300415\n",
      "2 6 0.8349946737289429\n",
      "2 7 0.8378738164901733\n",
      "2 8 0.8772842884063721\n",
      "2 9 0.7767167687416077\n",
      "2 10 0.731214702129364\n",
      "2 11 0.8312451839447021\n",
      "2 12 0.8585521578788757\n",
      "2 13 0.8480913639068604\n",
      "2 14 0.8177545070648193\n",
      "2 15 0.8935953974723816\n",
      "2 16 0.896104633808136\n",
      "2 17 0.9055670499801636\n",
      "3 0 0.9266768097877502\n",
      "3 1 0.934273898601532\n",
      "3 2 0.8904719352722168\n",
      "3 4 0.8137728571891785\n",
      "3 5 0.9018029570579529\n",
      "3 6 0.7765935659408569\n",
      "3 7 0.8974423408508301\n",
      "3 8 0.8732644319534302\n",
      "3 9 0.7911894917488098\n",
      "3 10 0.6537026166915894\n",
      "3 11 0.8393955230712891\n",
      "3 12 0.7897012829780579\n",
      "3 13 0.8611765503883362\n",
      "3 14 0.8519434928894043\n",
      "3 15 0.860836386680603\n",
      "3 16 0.8730605840682983\n",
      "3 17 0.863956868648529\n",
      "4 0 0.7899712324142456\n",
      "4 1 0.8224436640739441\n",
      "4 2 0.9118756055831909\n",
      "4 3 0.8137728571891785\n",
      "4 5 0.8563075065612793\n",
      "4 6 0.8687742948532104\n",
      "4 7 0.7772337198257446\n",
      "4 8 0.8928263187408447\n",
      "4 9 0.762672483921051\n",
      "4 10 0.8048157095909119\n",
      "4 11 0.8209701776504517\n",
      "4 12 0.8347955942153931\n",
      "4 13 0.8144192099571228\n",
      "4 14 0.7997976541519165\n",
      "4 15 0.8371779918670654\n",
      "4 16 0.8717737793922424\n",
      "4 17 0.8935245871543884\n",
      "5 0 0.925125002861023\n",
      "5 1 0.8933923840522766\n",
      "5 2 0.8857656717300415\n",
      "5 3 0.9018029570579529\n",
      "5 4 0.8563075065612793\n",
      "5 6 0.8920226097106934\n",
      "5 7 0.9287534356117249\n",
      "5 8 0.9025106430053711\n",
      "5 9 0.7990831732749939\n",
      "5 10 0.767318069934845\n",
      "5 11 0.9313843846321106\n",
      "5 12 0.8490746021270752\n",
      "5 13 0.9250929355621338\n",
      "5 14 0.9166395664215088\n",
      "5 15 0.915401816368103\n",
      "5 16 0.9386119246482849\n",
      "5 17 0.9418495297431946\n",
      "6 0 0.8560572862625122\n",
      "6 1 0.8096685409545898\n",
      "6 2 0.8349946737289429\n",
      "6 3 0.7765935659408569\n",
      "6 4 0.8687742948532104\n",
      "6 5 0.8920226097106934\n",
      "6 7 0.8646607398986816\n",
      "6 8 0.9055871963500977\n",
      "6 9 0.8178208470344543\n",
      "6 10 0.8416364192962646\n",
      "6 11 0.9332056641578674\n",
      "6 12 0.865345299243927\n",
      "6 13 0.8877655863761902\n",
      "6 14 0.8997330069541931\n",
      "6 15 0.9113937616348267\n",
      "6 16 0.9461956024169922\n",
      "6 17 0.9446773529052734\n",
      "7 0 0.9392214417457581\n",
      "7 1 0.8789430856704712\n",
      "7 2 0.8378738164901733\n",
      "7 3 0.8974423408508301\n",
      "7 4 0.7772337198257446\n",
      "7 5 0.9287534356117249\n",
      "7 6 0.8646607398986816\n",
      "7 8 0.883659303188324\n",
      "7 9 0.8215997815132141\n",
      "7 10 0.7659610509872437\n",
      "7 11 0.9243345856666565\n",
      "7 12 0.839834988117218\n",
      "7 13 0.9567528367042542\n",
      "7 14 0.9293438792228699\n",
      "7 15 0.9173112511634827\n",
      "7 16 0.932935893535614\n",
      "7 17 0.9262779355049133\n",
      "8 0 0.8979479670524597\n",
      "8 1 0.8916823863983154\n",
      "8 2 0.8772842884063721\n",
      "8 3 0.8732644319534302\n",
      "8 4 0.8928263187408447\n",
      "8 5 0.9025106430053711\n",
      "8 6 0.9055871963500977\n",
      "8 7 0.883659303188324\n",
      "8 9 0.9184709191322327\n",
      "8 10 0.8054972290992737\n",
      "8 11 0.898253858089447\n",
      "8 12 0.8364832401275635\n",
      "8 13 0.8992420434951782\n",
      "8 14 0.8822312951087952\n",
      "8 15 0.8856262564659119\n",
      "8 16 0.9176654815673828\n",
      "8 17 0.9367492198944092\n",
      "9 0 0.8055269718170166\n",
      "9 1 0.7799533009529114\n",
      "9 2 0.7767167687416077\n",
      "9 3 0.7911894917488098\n",
      "9 4 0.762672483921051\n",
      "9 5 0.7990831732749939\n",
      "9 6 0.8178208470344543\n",
      "9 7 0.8215997815132141\n",
      "9 8 0.9184709191322327\n",
      "9 10 0.705876886844635\n",
      "9 11 0.7960637807846069\n",
      "9 12 0.7712830901145935\n",
      "9 13 0.8144949674606323\n",
      "9 14 0.7933924198150635\n",
      "9 15 0.8187980055809021\n",
      "9 16 0.8254725933074951\n",
      "9 17 0.8209912776947021\n",
      "10 0 0.7147533297538757\n",
      "10 1 0.6866056323051453\n",
      "10 2 0.731214702129364\n",
      "10 3 0.6537026166915894\n",
      "10 4 0.8048157095909119\n",
      "10 5 0.767318069934845\n",
      "10 6 0.8416364192962646\n",
      "10 7 0.7659610509872437\n",
      "10 8 0.8054972290992737\n",
      "10 9 0.705876886844635\n",
      "10 11 0.8221797943115234\n",
      "10 12 0.8014922738075256\n",
      "10 13 0.8573811650276184\n",
      "10 14 0.8104715943336487\n",
      "10 15 0.8127650022506714\n",
      "10 16 0.836884617805481\n",
      "10 17 0.8507442474365234\n",
      "11 0 0.9197076559066772\n",
      "11 1 0.8543907999992371\n",
      "11 2 0.8312451839447021\n",
      "11 3 0.8393955230712891\n",
      "11 4 0.8209701776504517\n",
      "11 5 0.9313843846321106\n",
      "11 6 0.9332056641578674\n",
      "11 7 0.9243345856666565\n",
      "11 8 0.898253858089447\n",
      "11 9 0.7960637807846069\n",
      "11 10 0.8221797943115234\n",
      "11 12 0.8725828528404236\n",
      "11 13 0.929635763168335\n",
      "11 14 0.9527178406715393\n",
      "11 15 0.933615505695343\n",
      "11 16 0.9572416543960571\n",
      "11 17 0.9596985578536987\n",
      "12 0 0.8509125709533691\n",
      "12 1 0.7966938018798828\n",
      "12 2 0.8585521578788757\n",
      "12 3 0.7897012829780579\n",
      "12 4 0.8347955942153931\n",
      "12 5 0.8490746021270752\n",
      "12 6 0.865345299243927\n",
      "12 7 0.839834988117218\n",
      "12 8 0.8364832401275635\n",
      "12 9 0.7712830901145935\n",
      "12 10 0.8014922738075256\n",
      "12 11 0.8725828528404236\n",
      "12 13 0.8465052247047424\n",
      "12 14 0.8981213569641113\n",
      "12 15 0.9230929613113403\n",
      "12 16 0.9154880046844482\n",
      "12 17 0.8955406546592712\n",
      "13 0 0.904289960861206\n",
      "13 1 0.846263587474823\n",
      "13 2 0.8480913639068604\n",
      "13 3 0.8611765503883362\n",
      "13 4 0.8144192099571228\n",
      "13 5 0.9250929355621338\n",
      "13 6 0.8877655863761902\n",
      "13 7 0.9567528367042542\n",
      "13 8 0.8992420434951782\n",
      "13 9 0.8144949674606323\n",
      "13 10 0.8573811650276184\n",
      "13 11 0.929635763168335\n",
      "13 12 0.8465052247047424\n",
      "13 14 0.9252418279647827\n",
      "13 15 0.9254971146583557\n",
      "13 16 0.9433774352073669\n",
      "13 17 0.9425069093704224\n",
      "14 0 0.9377974271774292\n",
      "14 1 0.8611082434654236\n",
      "14 2 0.8177545070648193\n",
      "14 3 0.8519434928894043\n",
      "14 4 0.7997976541519165\n",
      "14 5 0.9166395664215088\n",
      "14 6 0.8997330069541931\n",
      "14 7 0.9293438792228699\n",
      "14 8 0.8822312951087952\n",
      "14 9 0.7933924198150635\n",
      "14 10 0.8104715943336487\n",
      "14 11 0.9527178406715393\n",
      "14 12 0.8981213569641113\n",
      "14 13 0.9252418279647827\n",
      "14 15 0.9324179887771606\n",
      "14 16 0.9452807307243347\n",
      "14 17 0.9287722706794739\n",
      "15 0 0.9032106399536133\n",
      "15 1 0.8446451425552368\n",
      "15 2 0.8935953974723816\n",
      "15 3 0.860836386680603\n",
      "15 4 0.8371779918670654\n",
      "15 5 0.915401816368103\n",
      "15 6 0.9113937616348267\n",
      "15 7 0.9173112511634827\n",
      "15 8 0.8856262564659119\n",
      "15 9 0.8187980055809021\n",
      "15 10 0.8127650022506714\n",
      "15 11 0.933615505695343\n",
      "15 12 0.9230929613113403\n",
      "15 13 0.9254971146583557\n",
      "15 14 0.9324179887771606\n",
      "15 16 0.9624344706535339\n",
      "15 17 0.9446951746940613\n",
      "16 0 0.9278295636177063\n",
      "16 1 0.8605772852897644\n",
      "16 2 0.896104633808136\n",
      "16 3 0.8730605840682983\n",
      "16 4 0.8717737793922424\n",
      "16 5 0.9386119246482849\n",
      "16 6 0.9461956024169922\n",
      "16 7 0.932935893535614\n",
      "16 8 0.9176654815673828\n",
      "16 9 0.8254725933074951\n",
      "16 10 0.836884617805481\n",
      "16 11 0.9572416543960571\n",
      "16 12 0.9154880046844482\n",
      "16 13 0.9433774352073669\n",
      "16 14 0.9452807307243347\n",
      "16 15 0.9624344706535339\n",
      "16 17 0.9730556607246399\n",
      "17 0 0.9142584204673767\n",
      "17 1 0.8662689924240112\n",
      "17 2 0.9055670499801636\n",
      "17 3 0.863956868648529\n",
      "17 4 0.8935245871543884\n",
      "17 5 0.9418495297431946\n",
      "17 6 0.9446773529052734\n",
      "17 7 0.9262779355049133\n",
      "17 8 0.9367492198944092\n",
      "17 9 0.8209912776947021\n",
      "17 10 0.8507442474365234\n",
      "17 11 0.9596985578536987\n",
      "17 12 0.8955406546592712\n",
      "17 13 0.9425069093704224\n",
      "17 14 0.9287722706794739\n",
      "17 15 0.9446951746940613\n",
      "17 16 0.9730556607246399\n",
      "0.867922717060139\n"
     ]
    }
   ],
   "source": [
    "for i, sent1 in enumerate(doc.sents):\n",
    "    for j, sent2 in enumerate(doc.sents):\n",
    "        if i == j:\n",
    "            continue\n",
    "        print(i, j, sent1.similarity(sent2))\n",
    "#The code down below gives the average similarity of the sentences in the document\n",
    "total = 0\n",
    "comparisons = 0\n",
    "for i, sent1 in enumerate(doc.sents):\n",
    "    for j, sent2 in enumerate(doc.sents):\n",
    "        if i == j:\n",
    "            continue\n",
    "        total += sent1.similarity(sent2)\n",
    "        comparisons += 1\n",
    "print(total/comparisons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to render the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"1e427dfd94c247d7ae1cebd19135e288-0\" class=\"displacy\" width=\"2325\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Our</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">review</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">discusses</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">landmarks</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">language</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">acquisition</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">as</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">well</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">as</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">their</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">biological</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">underpinnings.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1e427dfd94c247d7ae1cebd19135e288-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,264.5 210.0,264.5 210.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1e427dfd94c247d7ae1cebd19135e288-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1e427dfd94c247d7ae1cebd19135e288-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,264.5 385.0,264.5 385.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1e427dfd94c247d7ae1cebd19135e288-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,354.0 L237,342.0 253,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1e427dfd94c247d7ae1cebd19135e288-0-2\" stroke-width=\"2px\" d=\"M420,352.0 C420,264.5 560.0,264.5 560.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1e427dfd94c247d7ae1cebd19135e288-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M560.0,354.0 L568.0,342.0 552.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1e427dfd94c247d7ae1cebd19135e288-0-3\" stroke-width=\"2px\" d=\"M595,352.0 C595,264.5 735.0,264.5 735.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1e427dfd94c247d7ae1cebd19135e288-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M735.0,354.0 L743.0,342.0 727.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1e427dfd94c247d7ae1cebd19135e288-0-4\" stroke-width=\"2px\" d=\"M945,352.0 C945,264.5 1085.0,264.5 1085.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1e427dfd94c247d7ae1cebd19135e288-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,354.0 L937,342.0 953,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1e427dfd94c247d7ae1cebd19135e288-0-5\" stroke-width=\"2px\" d=\"M770,352.0 C770,177.0 1090.0,177.0 1090.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1e427dfd94c247d7ae1cebd19135e288-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1090.0,354.0 L1098.0,342.0 1082.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1e427dfd94c247d7ae1cebd19135e288-0-6\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,177.0 1615.0,177.0 1615.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1e427dfd94c247d7ae1cebd19135e288-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,354.0 L1287,342.0 1303,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1e427dfd94c247d7ae1cebd19135e288-0-7\" stroke-width=\"2px\" d=\"M1470,352.0 C1470,264.5 1610.0,264.5 1610.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1e427dfd94c247d7ae1cebd19135e288-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,354.0 L1462,342.0 1478,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1e427dfd94c247d7ae1cebd19135e288-0-8\" stroke-width=\"2px\" d=\"M595,352.0 C595,89.5 1620.0,89.5 1620.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1e427dfd94c247d7ae1cebd19135e288-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1620.0,354.0 L1628.0,342.0 1612.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1e427dfd94c247d7ae1cebd19135e288-0-9\" stroke-width=\"2px\" d=\"M1820,352.0 C1820,177.0 2140.0,177.0 2140.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1e427dfd94c247d7ae1cebd19135e288-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1820,354.0 L1812,342.0 1828,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1e427dfd94c247d7ae1cebd19135e288-0-10\" stroke-width=\"2px\" d=\"M1995,352.0 C1995,264.5 2135.0,264.5 2135.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1e427dfd94c247d7ae1cebd19135e288-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1995,354.0 L1987,342.0 2003,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1e427dfd94c247d7ae1cebd19135e288-0-11\" stroke-width=\"2px\" d=\"M595,352.0 C595,2.0 2150.0,2.0 2150.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1e427dfd94c247d7ae1cebd19135e288-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2150.0,354.0 L2158.0,342.0 2142.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "#displacy.serve(doc, style='dep', port=5002)\n",
    "# While using jupyter notebooks using .render instead of .serve is much better\n",
    "sentence_lists = list(doc.sents)\n",
    "displacy.render(sentence_lists[9], style='dep')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code down below creates a list for all sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_lists = list(doc.sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A way to render long docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#displacy.render(sentence_lists, style='dep')\n",
    "displacy.serve(sentence_lists, style='dep', port=5002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting results as visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10567"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "sentence1 = sentence_lists[9]\n",
    "svg = displacy.render(sentence1, style='dep', jupyter=False)\n",
    "filename = 'sentence1.svg'\n",
    "output_path = Path('/Users/alp/Desktop/Spacey/images' + filename)\n",
    "output_path.open('w', encoding='utf-8').write(svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of all tokens in a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our\n",
      "review\n",
      "discusses\n",
      "landmarks\n",
      "in\n",
      "language\n",
      "acquisition\n",
      "as\n",
      "well\n",
      "as\n",
      "their\n",
      "biological\n",
      "underpinnings\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "sentence1 = sentence_lists[9]\n",
    "for token in sentence1:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“Tokenization simply means splitting the sentence into its tokens. A token is a unit of semantics. You can think of a token as the smallest meaningful part of a piece of text. Tokens can be words, numbers, punctuation, currency symbols, and any other meaningful symbols that are the building blocks of a sentence.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part of the speach matched with tokens\n",
    "[POS link](https://universaldependencies.org/u/pos/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our review discusses landmarks in language acquisition as well as their biological underpinnings.\n",
      "['Our', 'review', 'discusses', 'landmarks', 'in', 'language', 'acquisition', 'as', 'well', 'as', 'their', 'biological', 'underpinnings', '.']\n",
      "[('Our', 'PRON'), ('review', 'NOUN'), ('discusses', 'VERB'), ('landmarks', 'NOUN'), ('in', 'ADP'), ('language', 'NOUN'), ('acquisition', 'NOUN'), ('as', 'ADV'), ('well', 'ADV'), ('as', 'ADP'), ('their', 'PRON'), ('biological', 'ADJ'), ('underpinnings', 'NOUN'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "sentence1 = sentence_lists[9]\n",
    "print(sentence1)\n",
    "#Create a list of tokens in the sentence1\n",
    "tokens = [token.text for token in sentence1]\n",
    "print(tokens)\n",
    "#Create a list of part-of-speech tags in the sentence1\n",
    "pos_tags = [token.pos_ for token in sentence1]\n",
    "ziped = zip(tokens, pos_tags)\n",
    "print(list(ziped))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the second half of the twentieth century DATE\n",
      "the first years DATE\n",
      "Chomsky PERSON\n",
      "1959 DATE\n",
      "Chomsky PERSON\n",
      "1959 DATE\n",
      "A few years later DATE\n",
      "Lenneberg 1967 ORG\n",
      "Elman PERSON\n",
      "Tomasello 2000 PERSON\n",
      "the first year DATE\n",
      "the next decades DATE\n",
      "first ORDINAL\n",
      "the past decades DATE\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The emergence of language has intrigued scientists and the general public alike, but it was only in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the second half of the twentieth century\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " that a systematic empirical investigation of language acquisition began. This work was greatly inspired by the suggestion that the environment is mainly a trigger rather than a tutor for language acquisition, at least during \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the first years\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " of life (\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Chomsky\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1959\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "). Consequently, to explain the uniquely human capacity of language, scholars proposed innate acquisition mechanisms, specific to language (\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Chomsky\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1959\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "). \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    A few years later\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", research into the biological foundations of language was expanded, giving a better grasp of the innate dispositions</br>for language acquisition (\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Lenneberg 1967\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "). </br>By contrast, other researchers suggested that classical learning mechanisms, ones that humans share with other animals, may be sufficient to acquire language (\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Elman\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " 1996, \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tomasello 2000\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "). Under this view, the human specificity of language arises from quantitative rather than qualitative differences between the species.</br>Some of these theoretical questions may be resolved by studying preverbal infants, in particular newborns, as this allows us to determine how much of our language acquisition abilities are due to dispositions detectable much before the surroundings have shaped our cognitive apparatus. Therefore, our review mostly focuses on the development of language</br>and its underlying mechanisms during \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the first year\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " of life. </br>This choice is also justified by the growing body of research and recent advances in understanding how different mechanisms, such as statistical and distributional learning, rule extraction, as well as perceptual and memory constraints, work together during language development.</br>Our review discusses landmarks in language acquisition as well as their biological underpinnings. We focus on studies that connect brain, mind, and behavior. We believe that building bridges between these different levels is the way of the future and that \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the next decades\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " will see the success of such integrative methodology and theory building.</br>In the review, we \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    first\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " describe the different theoretical approaches to language acquisition. We then review the increasingly important and fast-growing body of literature on the biological foundations of human language, focusing mostly on genetic and evolutionary aspects. Then we review the empirical evidence that has accumulated over \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the past decades\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " in support of the theories and approaches introduced. We discuss the findings following the levels of organization in language from phonology through word segmentation and lexical acquisition to grammar. Finally, we consider some of the novel empirical findings that relate to the neural basis of language acquisition and processing in newborns and young infants. Building on these empirical findings, we argue for an integrative theory of language acquisition, proposing that rule learning, perceptual bootstrapping, and statistical learning all contribute to different levels of language acquisition, and that the most interesting objective is to understand their interactions and the division of labor among them.</br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The emergence NP emergence\n",
      "language NP language\n",
      "scientists NP scientists\n",
      "the general public NP public\n",
      "it NP it\n",
      "the second half NP half\n",
      "the twentieth century NP century\n",
      "a systematic empirical investigation NP investigation\n",
      "language acquisition NP acquisition\n",
      "This work NP work\n",
      "the suggestion NP suggestion\n",
      "the environment NP environment\n",
      "a trigger NP trigger\n",
      "a tutor NP tutor\n",
      "language acquisition NP acquisition\n",
      "the first years NP years\n",
      "life NP life\n",
      "Chomsky NP Chomsky\n",
      "the uniquely human capacity NP capacity\n",
      "language NP language\n",
      "scholars NP scholars\n",
      "innate acquisition mechanisms NP mechanisms\n",
      "language NP language\n",
      "Chomsky NP Chomsky\n",
      "research NP research\n",
      "the biological foundations NP foundations\n",
      "language NP language\n",
      "a better grasp NP grasp\n",
      "the innate dispositions NP dispositions\n",
      "language acquisition NP acquisition\n",
      "Lenneberg NP Lenneberg\n",
      "contrast NP contrast\n",
      "other researchers NP researchers\n",
      "classical learning mechanisms NP mechanisms\n",
      "ones NP ones\n",
      "that NP that\n",
      "humans NP humans\n",
      "other animals NP animals\n",
      "language NP language\n",
      "Elman NP Elman\n",
      "Tomasello NP Tomasello\n",
      "this view NP view\n",
      "the human specificity NP specificity\n",
      "language NP language\n",
      "quantitative NP quantitative\n",
      "qualitative differences NP differences\n",
      "the species NP species\n",
      "Some NP Some\n",
      "these theoretical questions NP questions\n",
      "preverbal infants NP infants\n",
      "particular newborns NP newborns\n",
      "this NP this\n",
      "us NP us\n",
      "our language acquisition abilities NP abilities\n",
      "dispositions NP dispositions\n",
      "the surroundings NP surroundings\n",
      "our cognitive apparatus NP apparatus\n",
      "our review NP review\n",
      "the development NP development\n",
      "language NP language\n",
      "its underlying mechanisms NP mechanisms\n",
      "the first year NP year\n",
      "life NP life\n",
      "This choice NP choice\n",
      "the growing body NP body\n",
      "research NP research\n",
      "recent advances NP advances\n",
      "how different mechanisms NP mechanisms\n",
      "statistical and distributional learning NP learning\n",
      "rule extraction NP extraction\n",
      "perceptual and memory constraints NP constraints\n",
      "language development NP development\n",
      "Our review NP review\n",
      "landmarks NP landmarks\n",
      "language acquisition NP acquisition\n",
      "their biological underpinnings NP underpinnings\n",
      "We NP We\n",
      "studies NP studies\n",
      "that NP that\n",
      "brain NP brain\n",
      "mind NP mind\n",
      "behavior NP behavior\n",
      "We NP We\n",
      "bridges NP bridges\n",
      "these different levels NP levels\n",
      "the way NP way\n",
      "the future NP future\n",
      "the next decades NP decades\n",
      "the success NP success\n",
      "such integrative methodology and theory building NP building\n",
      "the review NP review\n",
      "we NP we\n",
      "the different theoretical approaches NP approaches\n",
      "language acquisition NP acquisition\n",
      "We NP We\n",
      "the increasingly important and fast-growing body NP body\n",
      "literature NP literature\n",
      "the biological foundations NP foundations\n",
      "human language NP language\n",
      "genetic and evolutionary aspects NP aspects\n",
      "we NP we\n",
      "the empirical evidence NP evidence\n",
      "that NP that\n",
      "the past decades NP decades\n",
      "support NP support\n",
      "the theories NP theories\n",
      "approaches NP approaches\n",
      "We NP We\n",
      "the findings NP findings\n",
      "the levels NP levels\n",
      "organization NP organization\n",
      "language NP language\n",
      "phonology NP phonology\n",
      "word segmentation NP segmentation\n",
      "lexical acquisition NP acquisition\n",
      "grammar NP grammar\n",
      "we NP we\n",
      "some NP some\n",
      "the novel empirical findings NP findings\n",
      "that NP that\n",
      "the neural basis NP basis\n",
      "language acquisition NP acquisition\n",
      "processing NP processing\n",
      "newborns NP newborns\n",
      "young infants NP infants\n",
      "these empirical findings NP findings\n",
      "we NP we\n",
      "an integrative theory NP theory\n",
      "language acquisition NP acquisition\n",
      "rule learning NP learning\n",
      "perceptual bootstrapping NP bootstrapping\n",
      "statistical learning NP learning\n",
      "different levels NP levels\n",
      "language acquisition NP acquisition\n",
      "the most interesting objective NP objective\n",
      "their interactions NP interactions\n",
      "the division NP division\n",
      "labor NP labor\n",
      "them NP them\n"
     ]
    }
   ],
   "source": [
    "for obj in doc.noun_chunks:\n",
    "    print(obj.text, obj.label_, obj.root.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A smiliraty matrix for each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our -> review -> 0.1353009194135666\n",
      "Our -> discusses -> 0.09265071153640747\n",
      "Our -> landmarks -> -0.0053463284857571125\n",
      "Our -> in -> 0.030499719083309174\n",
      "Our -> language -> 0.02306048572063446\n",
      "Our -> acquisition -> 0.12261588126420975\n",
      "Our -> as -> 0.06830637156963348\n",
      "Our -> well -> 0.08253715187311172\n",
      "Our -> as -> 0.06830637156963348\n",
      "Our -> their -> 0.31158027052879333\n",
      "Our -> biological -> 0.11669295281171799\n",
      "Our -> underpinnings -> 0.16561120748519897\n",
      "Our -> . -> 0.14620058238506317\n",
      "review -> Our -> 0.1353009194135666\n",
      "review -> discusses -> 0.4760911166667938\n",
      "review -> landmarks -> 0.16541312634944916\n",
      "review -> in -> 0.03355959430336952\n",
      "review -> language -> 0.26037272810935974\n",
      "review -> acquisition -> 0.43741652369499207\n",
      "review -> as -> 0.05098135396838188\n",
      "review -> well -> 0.1828746646642685\n",
      "review -> as -> 0.05098135396838188\n",
      "review -> their -> 0.10308544337749481\n",
      "review -> biological -> 0.26503872871398926\n",
      "review -> underpinnings -> 0.3863060176372528\n",
      "review -> . -> 0.09801000356674194\n",
      "discusses -> Our -> 0.09265071153640747\n",
      "discusses -> review -> 0.4760911166667938\n",
      "discusses -> landmarks -> 0.17219725251197815\n",
      "discusses -> in -> 0.21878840029239655\n",
      "discusses -> language -> 0.35807278752326965\n",
      "discusses -> acquisition -> 0.42322880029678345\n",
      "discusses -> as -> 0.17252923548221588\n",
      "discusses -> well -> 0.2782473564147949\n",
      "discusses -> as -> 0.17252923548221588\n",
      "discusses -> their -> 0.24524973332881927\n",
      "discusses -> biological -> 0.5153908729553223\n",
      "discusses -> underpinnings -> 0.5751909613609314\n",
      "discusses -> . -> 0.23153503239154816\n",
      "landmarks -> Our -> -0.0053463284857571125\n",
      "landmarks -> review -> 0.16541312634944916\n",
      "landmarks -> discusses -> 0.17219725251197815\n",
      "landmarks -> in -> 0.31025269627571106\n",
      "landmarks -> language -> 0.23233766853809357\n",
      "landmarks -> acquisition -> 0.2823253571987152\n",
      "landmarks -> as -> 0.2212749421596527\n",
      "landmarks -> well -> 0.22475184500217438\n",
      "landmarks -> as -> 0.2212749421596527\n",
      "landmarks -> their -> 0.15316706895828247\n",
      "landmarks -> biological -> 0.20035459101200104\n",
      "landmarks -> underpinnings -> 0.4252189099788666\n",
      "landmarks -> . -> 0.23023079335689545\n",
      "in -> Our -> 0.030499719083309174\n",
      "in -> review -> 0.03355959430336952\n",
      "in -> discusses -> 0.21878840029239655\n",
      "in -> landmarks -> 0.31025269627571106\n",
      "in -> language -> 0.2179897129535675\n",
      "in -> acquisition -> 0.3094726502895355\n",
      "in -> as -> 0.24509811401367188\n",
      "in -> well -> 0.2074853777885437\n",
      "in -> as -> 0.24509811401367188\n",
      "in -> their -> 0.26129886507987976\n",
      "in -> biological -> 0.3020015358924866\n",
      "in -> underpinnings -> 0.3421189486980438\n",
      "in -> . -> 0.3580297529697418\n",
      "language -> Our -> 0.02306048572063446\n",
      "language -> review -> 0.26037272810935974\n",
      "language -> discusses -> 0.35807278752326965\n",
      "language -> landmarks -> 0.23233766853809357\n",
      "language -> in -> 0.2179897129535675\n",
      "language -> acquisition -> 0.385715126991272\n",
      "language -> as -> 0.24737650156021118\n",
      "language -> well -> 0.33189380168914795\n",
      "language -> as -> 0.24737650156021118\n",
      "language -> their -> 0.30631330609321594\n",
      "language -> biological -> 0.47978726029396057\n",
      "language -> underpinnings -> 0.40648844838142395\n",
      "language -> . -> 0.21089249849319458\n",
      "acquisition -> Our -> 0.12261588126420975\n",
      "acquisition -> review -> 0.43741652369499207\n",
      "acquisition -> discusses -> 0.42322880029678345\n",
      "acquisition -> landmarks -> 0.2823253571987152\n",
      "acquisition -> in -> 0.3094726502895355\n",
      "acquisition -> language -> 0.385715126991272\n",
      "acquisition -> as -> 0.2504347264766693\n",
      "acquisition -> well -> 0.29743608832359314\n",
      "acquisition -> as -> 0.2504347264766693\n",
      "acquisition -> their -> 0.37746143341064453\n",
      "acquisition -> biological -> 0.5051313042640686\n",
      "acquisition -> underpinnings -> 0.5806992650032043\n",
      "acquisition -> . -> 0.2412036955356598\n",
      "as -> Our -> 0.06830637156963348\n",
      "as -> review -> 0.05098135396838188\n",
      "as -> discusses -> 0.17252923548221588\n",
      "as -> landmarks -> 0.2212749421596527\n",
      "as -> in -> 0.24509811401367188\n",
      "as -> language -> 0.24737650156021118\n",
      "as -> acquisition -> 0.2504347264766693\n",
      "as -> well -> 0.4017060399055481\n",
      "as -> as -> 1.0\n",
      "as -> their -> 0.25643688440322876\n",
      "as -> biological -> 0.3047630488872528\n",
      "as -> underpinnings -> 0.2878156900405884\n",
      "as -> . -> 0.2501402497291565\n",
      "well -> Our -> 0.08253715187311172\n",
      "well -> review -> 0.1828746646642685\n",
      "well -> discusses -> 0.2782473564147949\n",
      "well -> landmarks -> 0.22475184500217438\n",
      "well -> in -> 0.2074853777885437\n",
      "well -> language -> 0.33189380168914795\n",
      "well -> acquisition -> 0.29743608832359314\n",
      "well -> as -> 0.4017060399055481\n",
      "well -> as -> 0.4017060399055481\n",
      "well -> their -> 0.40708836913108826\n",
      "well -> biological -> 0.35660821199417114\n",
      "well -> underpinnings -> 0.4291616678237915\n",
      "well -> . -> 0.30535662174224854\n",
      "as -> Our -> 0.06830637156963348\n",
      "as -> review -> 0.05098135396838188\n",
      "as -> discusses -> 0.17252923548221588\n",
      "as -> landmarks -> 0.2212749421596527\n",
      "as -> in -> 0.24509811401367188\n",
      "as -> language -> 0.24737650156021118\n",
      "as -> acquisition -> 0.2504347264766693\n",
      "as -> as -> 1.0\n",
      "as -> well -> 0.4017060399055481\n",
      "as -> their -> 0.25643688440322876\n",
      "as -> biological -> 0.3047630488872528\n",
      "as -> underpinnings -> 0.2878156900405884\n",
      "as -> . -> 0.2501402497291565\n",
      "their -> Our -> 0.31158027052879333\n",
      "their -> review -> 0.10308544337749481\n",
      "their -> discusses -> 0.24524973332881927\n",
      "their -> landmarks -> 0.15316706895828247\n",
      "their -> in -> 0.26129886507987976\n",
      "their -> language -> 0.30631330609321594\n",
      "their -> acquisition -> 0.37746143341064453\n",
      "their -> as -> 0.25643688440322876\n",
      "their -> well -> 0.40708836913108826\n",
      "their -> as -> 0.25643688440322876\n",
      "their -> biological -> 0.4207007884979248\n",
      "their -> underpinnings -> 0.4674527645111084\n",
      "their -> . -> 0.3892056941986084\n",
      "biological -> Our -> 0.11669295281171799\n",
      "biological -> review -> 0.26503872871398926\n",
      "biological -> discusses -> 0.5153908729553223\n",
      "biological -> landmarks -> 0.20035459101200104\n",
      "biological -> in -> 0.3020015358924866\n",
      "biological -> language -> 0.47978726029396057\n",
      "biological -> acquisition -> 0.5051313042640686\n",
      "biological -> as -> 0.3047630488872528\n",
      "biological -> well -> 0.35660821199417114\n",
      "biological -> as -> 0.3047630488872528\n",
      "biological -> their -> 0.4207007884979248\n",
      "biological -> underpinnings -> 0.5311771035194397\n",
      "biological -> . -> 0.32286399602890015\n",
      "underpinnings -> Our -> 0.16561120748519897\n",
      "underpinnings -> review -> 0.3863060176372528\n",
      "underpinnings -> discusses -> 0.5751909613609314\n",
      "underpinnings -> landmarks -> 0.4252189099788666\n",
      "underpinnings -> in -> 0.3421189486980438\n",
      "underpinnings -> language -> 0.40648844838142395\n",
      "underpinnings -> acquisition -> 0.5806992650032043\n",
      "underpinnings -> as -> 0.2878156900405884\n",
      "underpinnings -> well -> 0.4291616678237915\n",
      "underpinnings -> as -> 0.2878156900405884\n",
      "underpinnings -> their -> 0.4674527645111084\n",
      "underpinnings -> biological -> 0.5311771035194397\n",
      "underpinnings -> . -> 0.41696229577064514\n",
      ". -> Our -> 0.14620058238506317\n",
      ". -> review -> 0.09801000356674194\n",
      ". -> discusses -> 0.23153503239154816\n",
      ". -> landmarks -> 0.23023079335689545\n",
      ". -> in -> 0.3580297529697418\n",
      ". -> language -> 0.21089249849319458\n",
      ". -> acquisition -> 0.2412036955356598\n",
      ". -> as -> 0.2501402497291565\n",
      ". -> well -> 0.30535662174224854\n",
      ". -> as -> 0.2501402497291565\n",
      ". -> their -> 0.3892056941986084\n",
      ". -> biological -> 0.32286399602890015\n",
      ". -> underpinnings -> 0.41696229577064514\n"
     ]
    }
   ],
   "source": [
    "sentence1 = sentence_lists[9]\n",
    "for token1 in sentence1:\n",
    "    for token2 in sentence1:\n",
    "        if token1 == token2:\n",
    "            continue\n",
    "        print(token1.text, str(\"->\"), token2.text, str(\"->\"), token1.similarity(token2))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
